question;answer;explanation
---
"Est√°s trabajando en la automatizaci√≥n de la salida de piezas de una m√°quina fresadora para que un robot cartesiano pueda coger la pieza producida en la misma y la lleve a la estanter√≠a donde se almacena temporalmente antes de su empaquetado y env√≠o al cliente. La empresa trabaja con un total de 10 piezas distintas que la fresadora va construyendo de forma automatizada..

...has dise√±ado un modelo usando keras que emplea el c√≥digo de la figura.¬øPodr√≠as identificar los 2 errores que hay en el c√≥digo, las implicaciones que tendr√≠an y c√≥mo solucionarlos?

<pre><code class="python">

model = tf.keras.models.Sequential([
    # Primera capa convolucional
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    tf.keras.layers.MaxPooling2D((2, 2)),

    # Segunda capa convolucional
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),

    # Tercera capa convolucional
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),

    # Proceso de regularizaci√≥n con dropout con una desactivaci√≥n del 50% de las neuronas
    tf.keras.layers.Dropout(0.5),

    # Capa oculta de 512 neuronas
    tf.keras.layers.Dense(512, activation='relu'),

    # Capa de salida de 7 neuronas
    tf.keras.layers.Dense(7, activation='softmax')
])

model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

history = model.fit(x, y, epochs=20, verbose=1, validation_data=(X_t, y_t))


</code></pre>

:
A. No est√°n bien las capas de Convoluci√≥n.
B. Falta una tf.keras.Flatten(), antes de Dense.
C. Pocas neuronas en la salida.
D. Demasiadas neuronas en la salida.";"B,C";"Hay dos errores
- Err1 - nos falta aplanar el vector a 1D antes de enviarlo a la capa Dense.

- Err2 - Si vamos a clasificar 10 items o 20 o los que sea no podemos tener menos neuronas a la salida.


- Mediante el uso de operaciones de convoluci√≥n y pooling, las CNN reducen la cantidad de par√°metros necesarios, haciendo que el modelo sea m√°s eficiente y menos propenso al sobreajuste. Esto es clave para trabajar con im√°genes grandes.

- Las CNN reutilizan los mismos filtros en diferentes partes de la imagen, lo que reduce los c√°lculos y mejora la generalizaci√≥n, ya que el modelo aprende caracter√≠sticas comunes en toda la imagen. Esto es crucial para problemas de visi√≥n por computadora.

- Las redes convolucionales son ideales para im√°genes porque capturan caracter√≠sticas autom√°ticamente, son computacionalmente eficientes y permiten la reutilizaci√≥n de pesos. Estas ventajas las han convertido en el est√°ndar para problemas de visi√≥n por computadora.

<a target="_blank" href="https://data-universe.org/redes-neuronales-convolucionales-aplicaciones-en-procesamiento-de-imagenes/">CNN procesamiento im√°genes</a>


Pooling, como el max pooling o el average pooling, es una t√©cnica utilizada en redes convolucionales para reducir la dimensionalidad espacial (alto y ancho) de los mapas de caracter√≠sticas. Esto se realiza seleccionando los valores m√°s importantes de regiones peque√±as del mapa de caracter√≠sticas.

    - Dropout no elimina neuronas de forma permanente, solo las "desactiva" temporalmente durante el entrenamiento.

- Dropout funciona al desactivar aleatoriamente neuronas durante el entrenamiento, lo que ayuda a la red a aprender representaciones m√°s generales y evita el sobreajuste.

- Dropout S√ç afecta directamente a las neuronas, no solo a las conexiones.

- Dropout NO es exclusivo de redes recurrentes- se aplica en redes convolucionales (CNN), densas (Dense) y recurrentes (RNN).

<a target="_blank" href="https://es.wikipedia.org/wiki/Abandono_(redes_neuronales)">
Dropout / Abandono RRNN
</a>

<h4>¬øQu√© es Dropout?</h4>

Dropout es una t√©cnica regularizadora utilizada en redes neuronales para reducir el riesgo de overfitting (sobreajuste). Durante el entrenamiento, se desactivan aleatoriamente un porcentaje de neuronas en cada iteraci√≥n, lo que significa que estas neuronas no contribuyen ni al c√°lculo hacia adelante (forward pass) ni a la retropropagaci√≥n (backpropagation). Al hacer esto, se fuerza a la red a no depender excesivamente de neuronas espec√≠ficas, oblig√°ndola a aprender patrones m√°s generales y robustos en los datos de entrada.

"
---
"¬øQu√© ocurre al inicializar todos los pesos y sesgos a cero en un clasificador lineal?:
A. Da como resultado un aprendizaje m√°s r√°pido y con mejores resultados porque aumenta la velocidad de convergencia al tener la matriz W el mismo valor en todos sus elementos.
B. Genera un modelo inicial que converge m√°s r√°pido pero puede llevar a un modelo sub√≥ptimo debido a la falta de diversidad en los pesos.
C. No afecta significativamente al aprendizaje, pero reduce la variabilidad inicial del modelo.
D. Impide que el modelo aprenda correctamente, ya que todos los elementos de la matriz W tienen el mismo valor y no permite la diferenciaci√≥n de caracter√≠sticas durante el entrenamiento.";"D";"Inicializar todos los pesos y sesgos a cero en un clasificador lineal resulta problem√°tico porque conduce a la simetr√≠a en las actualizaciones de los par√°metros durante el entrenamiento. En algoritmos como el gradiente descendente, todas las caracter√≠sticas se tratar√≠an de manera id√©ntica, y las actualizaciones para cada peso ser√≠an id√©nticas, impidiendo que el modelo aprenda a diferenciar la importancia relativa de las caracter√≠sticas. Esto se conoce como el problema de la simetr√≠a rota. <a target="_blank" href="https://en.wikipedia.org/wiki/Weight_initialization"/>link</a> Para garantizar un entrenamiento efectivo, es crucial inicializar los pesos con valores peque√±os y aleatorios, lo que introduce suficiente asimetr√≠a para que las caracter√≠sticas se actualicen de forma independiente, permitiendo al modelo aprender patrones significativos en los datos."
---
"Para un clasificador lineal, inicializar todos los pesos y sesgos a cero dar√° como resultado un aprendizaje m√°s r√°pido y con mejores resultados ya que aumenta la velocidad de convergencia pues todos los elementos de la matriz W contienen el mismo valor (mira luego la expli):
A. Cierto
B. No";"B";"Inicializar todos los pesos y sesgos a cero en un clasificador lineal no mejora el aprendizaje ni los resultados, ya que conduce al problema de simetr√≠a rota- <a target="_blank" href="https://en.wikipedia.org/wiki/Weight_initialization"/>link</a> Para garantizar un entrenamiento efectivo, es crucial inicializar los pesos con valores peque√±os y aleatorios, lo que introduce suficiente asimetr√≠a para que las caracter√≠sticas se actualicen de forma independiente, permitiendo al modelo aprender patrones significativos en los datos.

Los sesgos (bias) pueden inicializarse a cero sin causar problemas significativos en el aprendizaje de un modelo. A diferencia de los pesos, los sesgos no est√°n sujetos al problema de simetr√≠a rota, ya que su papel principal es desplazar las activaciones, y no participan en la ponderaci√≥n relativa de las entradas.
"
---
"Disponemos de un dataset peque√±o que contiene caracteres manuscritos de la A a la Z y queremos desarrollar un modelo de reconocimiento de escritura. Como el dataset es peque√±o, una buena idea es aumentar el conjunto de datos volteando aleatoriamente cada imagen horizontal y verticalmente, dado que sabemos que cada letra est√° representada por igual en el dataset original (mira exp):
A. Verdadero.
B. Falso";"B";"Voltear aleatoriamente las im√°genes horizontal y verticalmente no es una buena idea en este caso porque alterar√≠a la sem√°ntica de las letras. Por ejemplo, al voltear horizontalmente una "b" se parecer√≠a a una "d", y al voltear verticalmente una "u" podr√≠a parecer una "n". Esto introducir√≠a ruido en los datos y confundir√≠a al modelo durante el entrenamiento. Una mejor estrategia ser√≠a emplear aumentaciones que preserven las caracter√≠sticas distintivas de las letras, como rotaciones muy peque√±as, cambios en el brillo o ruido gaussiano, para enriquecer el conjunto de datos sin alterar la naturaleza de las letras <a target="_blank" href="https://arxiv.org/pdf/2308.13791">Enlace</a> "
---
"A√±adir capas de Batch Normalization ayuda a mitigar el problema del "Exploding Gradient".¬†Para cada apartado la puntuaci√≥n es la mitad por decir si es verdadero o falso y la otra mitad por indicar el motivo correctamente (expli):
A. Verdad
B. Nop";"A";"Las capas de Batch Normalization ayudan a mitigar el problema del exploding gradient (y tambi√©n el vanishing gradient) al normalizar las activaciones de cada capa, manteni√©ndolas dentro de un rango estable. Esto reduce el riesgo de que los gradientes crezcan exponencialmente durante el retropropagado en redes profundas, lo que podr√≠a saturar los valores de los pesos y dificultar la convergencia. Adem√°s, al mantener las activaciones m√°s consistentes, Batch Normalization contribuye a un entrenamiento m√°s estable y a una mayor eficiencia en la optimizaci√≥n. Sin embargo, aunque mitiga el problema, no lo resuelve por completo en casos extremos.

Es importante se√±alar que, en redes muy profundas, el Batch Normalization por s√≠ solo puede no ser suficiente para resolver completamente este problema. En algunos casos, se ha observado que puede incluso contribuir al fen√≥meno de explosi√≥n de gradientes si no se combina con otras t√©cnicas adecuadas, como las conexiones residuales.

Aunque el Batch Normalization es una herramienta √∫til para mitigar el problema del exploding gradient, su efectividad puede depender de la arquitectura espec√≠fica de la red y de su combinaci√≥n con otras t√©cnicas de normalizaci√≥n y regularizaci√≥n.
<a target="_blank" href="https://spotintelligence.com/2023/12/06/exploding-gradient-problem/?utm_source=chatgpt.com">Explo Grad</a>
"
---
"Est√°s entrenando una red GAN para generar im√°genes de puestas de sol en la playa usando im√°genes que has tomado en tus √∫ltimas vacaciones en Almer√≠a. Tienes un n√∫mero limitado de im√°genes y decides aplicar t√©cnicas de Data Augmentation para mejorar el entrenamiento de la red GAN. Para empezar, usas cuatro t√©cnicas de Data Augmentation que son bien conocidas. ¬øCu√°les de estas t√©cnicas crees que pueden ser una buena idea para ayudar a que la red GAN genere mejores im√°genes? mirar expli:
A. Cambiar el color de algunos p√≠xeles de forma aleatorio.
B. Voltear la imagen de izquierda a derecha.
C. Hacer recortes de partes de la imagen.
D. Aplicar desenfoques.";"B,C";" -Cambiar el color de algunos p√≠xeles de forma aleatoria.
No es una buena idea. Cambiar colores de p√≠xeles al azar introduce ruido en los datos y puede llevar a que el modelo aprenda patrones irreales o indeseados, ya que las im√°genes originales se distorsionan de forma no natural. Esto perjudica el realismo de las im√°genes generadas.

- Voltear la imagen de izquierda a derecha.
Es una buena idea. En el caso de las puestas de sol en la playa, voltear las im√°genes horizontalmente no altera la sem√°ntica de la escena y genera mayor diversidad en el conjunto de datos. Esto puede ayudar a la red GAN a aprender patrones m√°s variados.

- Hacer recortes de partes de la imagen.
Es una buena idea con precauci√≥n. Realizar recortes puede ser √∫til para forzar al modelo a aprender detalles locales y generar im√°genes m√°s realistas. Sin embargo, los recortes deben mantenerse dentro de un rango razonable para no perder el contexto general de las puestas de sol y la playa.

- Aplicar desenfoques.
Depende del objetivo. Aplicar desenfoques puede ser √∫til en ciertos casos para aprender a generar variaciones en profundidad de campo o para imitar condiciones espec√≠ficas. Sin embargo, si se usa excesivamente, podr√≠a generar un modelo que produzca im√°genes borrosas, lo que no es deseable en la mayor√≠a de los casos."
---
"Para poder detectar si en la imagen aparece un gato o no decides dise√±ar una Red Neur Convo con una neurona de salida y activaci√≥n ReLU. La salida de esta neurona es z. As√≠ la salida final y, de la neurona z, viene dada por la  expresi√≥n y = ReLU (z) Decides clasificar como gatos todos los valores de y>5.
¬øQu√© problema encuentras?:
A. La funci√≥n de activaci√≥n ReLU no permite clasificar correctamente valores por debajo de 0, ya que los resultados negativos de z se convierten en 0.
B. Clasificar bas√°ndote en y > 5 puede ser arbitrario y dificulta la interpretaci√≥n de los resultados del modelo.
C. La funci√≥n de activaci√≥n ReLU es inadecuada, ya que no permite manejar adecuadamente valores por encima del umbral de clasificaci√≥n.
D. La configuraci√≥n actual garantiza que siempre se clasifiquen todas las im√°genes correctamente como -gato- o -no gato-.";"A,B";"- La funci√≥n de activaci√≥n ReLU no permite clasificar correctamente valores por debajo de 0, ya que los resultados negativos de z se convierten en 0.
Correcto. Esto significa que las im√°genes que deber√≠an producir valores negativos de z no se distinguir√°n de aquellas con z cercano a 0, lo que puede llevar a errores en la clasificaci√≥n.

- Clasificar bas√°ndote en y > 5 puede ser arbitrario y dificulta la interpretaci√≥n de los resultados del modelo.
Correcto. Establecer un umbral como 5 sin un motivo claro no est√° respaldado por un criterio s√≥lido y podr√≠a afectar la precisi√≥n del modelo, ya que depende del rango de salida de z.

- La funci√≥n de activaci√≥n ReLU es inadecuada, ya que no permite manejar adecuadamente valores por encima del umbral de clasificaci√≥n.
Falso. ReLU es adecuada para manejar valores mayores que 0 y no presenta problemas con valores altos de z, el problema radica en la configuraci√≥n del umbral o la funci√≥n de decisi√≥n, no en ReLU misma.

- La configuraci√≥n actual garantiza que siempre se clasifiquen todas las im√°genes correctamente como "gato" o "no gato".
Falso. La configuraci√≥n no garantiza esto porque los valores de salida de y dependen de la distribuci√≥n de z, que puede no estar bien ajustada para clasificar efectivamente las im√°genes en base al umbral definido."
---
"Para poder detectar si en la imagen aparece un gato o no decides dise√±ar una Red Neur Convo con una neurona de salida y activaci√≥n ReLU. La salida de esta neurona es z. As√≠ la salida final y, de la neurona z, viene dada por la  expresi√≥n y = ReLU (z) Decides clasificar como gatos todos los valores de y>5.
¬øC√≥mo solucionas el problema que surge?:
A. Cambiar la funci√≥n de activaci√≥n de la neurona de salida a una funci√≥n sigmoide, que produce valores en el rango [0, 1], y ajustar el umbral de clasificaci√≥n.
B. Es sencillo - mantener la funci√≥n ReLU pero cambiar el umbral de clasificaci√≥n a y > 0
C. A√±adir una capa de normalizaci√≥n a la salida de la funci√≥n ReLU para que los valores de y est√©n en un rango adecuado antes de clasificar
D. Cambiar el criterio de clasificaci√≥n a "todos los valores de y > 1" para simplificar la decisi√≥n.";"A";"<a target="_blank" href="https://ml-explained.com/blog/activation-functions-explained">
<img src="https://ml-explained.com/_ipx/sizes_xs:320px%20md:768px%20lg:1024px,w_768,f_webp/articles/activation-functions-explained/Sigmoid_Function.png"/>
</a>
- Cambiar la funci√≥n de activaci√≥n de la neurona de salida a una funci√≥n sigmoide, que produce valores en el rango [0, 1], y ajustar el umbral de clasificaci√≥n.
Cierto. Cambiar a una funci√≥n sigmoide permite que la salida est√© en un rango bien definido, lo que facilita interpretar la probabilidad de que la imagen sea un gato. El umbral podr√≠a ajustarse, por ejemplo, a 0.5 para clasificar correctamente.

- Mantener la funci√≥n ReLU pero cambiar el umbral de clasificaci√≥n a y > 0.
Falso. Esto eliminar√≠a el problema de los valores negativos de z, pero no resuelve la arbitrariedad del umbral 5. Adem√°s, podr√≠a reducir la precisi√≥n de la clasificaci√≥n, ya que valores bajos positivos podr√≠an ser incorrectamente clasificados como gatos.

- A√±adir una capa de normalizaci√≥n a la salida de la funci√≥n ReLU para que los valores de y est√©n en un rango adecuado antes de clasificar.
Falso. La normalizaci√≥n de los valores de salida no resuelve el problema principal de la arbitrariedad del umbral ni la falta de interpretaci√≥n probabil√≠stica de la salida de ReLU.

- Cambiar el criterio de clasificaci√≥n a "todos los valores de y > 1" para simplificar la decisi√≥n.
Falso. Cambiar el umbral a 1 no resuelve el problema de fondo, ya que sigue siendo un criterio arbitrario y no ajustado a una escala probabil√≠stica.
"
---
"Qu√© afirmaciones sobre las Redes Neuronales Recurrentes (RNN) son correctas?:
A. Las RNN son redes dise√±adas para procesar secuencias de datos, como series temporales o texto, gracias a su capacidad para mantener informaci√≥n del pasado en sus c√°lculos.
B. Las RNN no tienen problemas para manejar dependencias a largo plazo en secuencias largas.
C. Las RNN pueden ser mejoradas mediante arquitecturas como LSTM o GRU, que est√°n dise√±adas para mitigar el problema de desvanecimiento del gradiente.
D. Una desventaja clave de las RNN es que no pueden procesar secuencias de diferentes longitudes.";"A,C";"
<a target="_blank" href="https://lamaquinaoraculo.com/deep-learning/redes-neuronales-recurrentes">RNN link</a>

<a target="_blank" href="https://www.themachinelearners.com/modelos-secuencia/">Modelos de Secuencia</a>

- Las RNN son redes dise√±adas para procesar secuencias de datos, como series temporales o texto, gracias a su capacidad para mantener informaci√≥n del pasado en sus c√°lculos.
Cierto. Esta es la principal caracter√≠stica de las RNN, ya que tienen conexiones recurrentes que permiten recordar estados previos.

- Las RNN no tienen problemas para manejar dependencias a largo plazo en secuencias largas.
Falso. Las RNN b√°sicas sufren del problema de desvanecimiento del gradiente, lo que dificulta aprender dependencias a largo plazo.

- Las RNN pueden ser mejoradas mediante arquitecturas como LSTM o GRU, que est√°n dise√±adas para mitigar el problema de desvanecimiento del gradiente.
Cierto. LSTM (Long Short-Term Memory) y GRU (Gated Recurrent Units) introducen mecanismos de memoria y puertas que les permiten aprender dependencias a largo plazo de manera m√°s efectiva.

- Una desventaja clave de las RNN es que no pueden procesar secuencias de diferentes longitudes.
Falso. Las RNN pueden procesar secuencias de diferentes longitudes gracias a su dise√±o recurrente.

Una Red Neuronal Recurrente (RNN) es un tipo de red neuronal dise√±ada espec√≠ficamente para procesar datos secuenciales, como series temporales, texto, o audio. A diferencia de redes como las densas (MLP) o convolucionales (CNN), las RNN tienen conexiones recurrentes que les permiten mantener un estado interno, lo cual es √∫til para capturar relaciones y patrones en secuencias.

En las RNN, cada paso de tiempo procesa un elemento de la secuencia y actualiza su estado interno para incorporar informaci√≥n previa. Esto les otorga la capacidad de modelar dependencias temporales, haciendo que sean ideales para tareas como traducci√≥n autom√°tica, an√°lisis de sentimientos y reconocimiento de voz.

Principales diferencias respecto a otras redes:

    Las RNN pueden manejar datos de longitud variable, mientras que las redes densas requieren entradas de tama√±o fijo.
    A diferencia de las CNN, que se especializan en datos espaciales, las RNN est√°n optimizadas para datos temporales o secuenciales.

Ventajas:

    Pueden capturar dependencias temporales en secuencias.
    Manejan datos de longitud variable.
    Son aptas para tareas como predicci√≥n de series temporales o procesamiento de lenguaje natural.

Desventajas:

    Desvanecimiento y explosi√≥n del gradiente: Las RNN b√°sicas tienen dificultades para aprender dependencias a largo plazo debido a problemas con los gradientes en el entrenamiento.
    Procesamiento secuencial: El c√°lculo secuencial limita la velocidad de entrenamiento y dificulta la paralelizaci√≥n.

T√©cnicas para mitigar desventajas:

    LSTM (Long Short-Term Memory): Introduce una arquitectura con "puertas" que controlan el flujo de informaci√≥n, resolviendo el problema del desvanecimiento del gradiente y permitiendo aprender dependencias a largo plazo.
    GRU (Gated Recurrent Unit): Simplifica las LSTM, logrando un desempe√±o similar con menos par√°metros.
    Regularizaci√≥n: T√©cnicas como Dropout en conexiones recurrentes ayudan a evitar sobreajuste.
    Bidireccional RNN: Procesan la secuencia en ambas direcciones para capturar contextos pasados y futuros.
    Transformers: Aunque no son RNN, los Transformers han demostrado ser m√°s eficientes para secuencias largas, reemplazando RNN en muchas aplicaciones modernas.
"
---
"En tu lugar de trabajo te han asignado un nuevo proyecto. Dada la confianza que tu empresa tiene en ti, te han dado acceso al dataset completo desde el primer momento.

Para empezar a trabajar has decidido utilizar los datos de los √∫ltimos 6 meses de forma que has utilizado los datos de los 5 primeros meses para entrenar un modelo basado en redes neuronales y el sexto mes para probarlo.¬†

Tras hacer muchas pruebas te sigue apareciendo de forma constante una diferencia muy grande entre el rendimiento de los datos de entrenamiento y los datos de prueba. Concretamente, el modelo funciona bien con los datos de entrenamiento pero le cuesta con los datos de prueba. ¬øCu√°l de las siguientes razones puede ser v√°lida para lo que te est√° sucediendo? (mira expli despu√©s)
(0.5 puntos seleccionar la opci√≥n correcta. 1.5 puntos explicar los motivos por los que esa es la opci√≥n correcta y las otras no):
A. El optimizador que usas es incorrecto y no es v√°lido para este problema.¬†
B. La funci√≥n de coste que est√°s utilizando no es correcta para este problema.¬†
C. Los datos de entrenamiento y de prueba no siguen la misma distribuci√≥n.
D. El modelo que usas no tiene la complejidad necesaria para capturar se√±ales relevantes en los datos, debes aumentar el n√∫mero de capas y/o de neuronas en cada capa.";"C";"Cuando el modelo funciona bien con los datos de entrenamiento pero tiene problemas con los datos de prueba, es un indicativo cl√°sico de desajuste de distribuci√≥n (data shift). Esto ocurre cuando los datos de entrenamiento y los de prueba no provienen de la misma distribuci√≥n o no representan el mismo fen√≥meno. Por ejemplo:

  - Estacionalidad: Si los datos abarcan diferentes per√≠odos de tiempo (ejemplo: 5 meses de entrenamiento y un sexto mes de prueba), puede haber un cambio en los patrones de los datos debido a estacionalidad, tendencias del mercado, eventos externos, etc.

  - Cambio en la fuente de datos: Podr√≠a haber una diferencia en c√≥mo se generan los datos del sexto mes respecto a los primeros cinco meses (por ejemplo, cambios en el proceso de recolecci√≥n de datos o caracter√≠sticas de los clientes).

  - Representatividad: Es posible que los datos de entrenamiento no representen suficientemente los patrones presentes en los datos de prueba.

El resto de opciones podr√≠an ser posibles pero no deber√≠an ya que se ha tenido suficiente tiempo para crear el modelo.
"
---
"Tras mucho tiempo trabajando has puesto en producci√≥n el √∫ltimo modelo que has creado haciendo uso de t√©cnicas Deep Learning como redes neuronales.
Est√°s muy ilusionado porque los datos de accuracy sobre tus datos de entrenamiento son excelentes.

Sin embargo, al poner el modelo en producci√≥n los resultados <b>no han sido para nada buenos üíÄ</b>.

Piensas que tu modelo puede sufrir overfitting. ¬øCu√°l de las siguientes t√©cnicas crees que pueden ayudar a reducci√≥n el overfitting sobre tus datos de entrenamiento? (Explica en qu√© consiste cada una de ellas y justifica por qu√© puede ayudar (o no) a reducir el overfitting - mira expli):
A. Early Stopping.
B. Dropout.
C. Data Augmentation.
D. Pooling.";"A,B,C";"<h4>Early Stopping</h4>

    ¬øEn qu√© consiste? Early stopping es una t√©cnica que detiene el entrenamiento del modelo cuando el rendimiento sobre los datos de validaci√≥n deja de mejorar durante varias √©pocas consecutivas. Esto evita que el modelo siga aprendiendo patrones espec√≠ficos de los datos de entrenamiento (sobreajuste).

    ¬øPor qu√© puede ayudar a reducir el overfitting? Si un modelo entrena durante demasiadas √©pocas, puede comenzar a memorizar los datos de entrenamiento en lugar de generalizar patrones. Al detener el entrenamiento justo antes de que esto ocurra, el modelo se queda en un punto √≥ptimo donde se minimiza el error de generalizaci√≥n.

    Ejemplo de implementaci√≥n en Keras

<pre><code class="python">
    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
    model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[early_stopping])
</code></pre>

<h4>Dropout</h4>

    ¬øEn qu√© consiste? Dropout es una t√©cnica de regularizaci√≥n que, durante el entrenamiento, "apaga" aleatoriamente un porcentaje de neuronas en una capa. Esto evita que las neuronas dependan demasiado unas de otras y fomenta que el modelo aprenda representaciones m√°s generalizables.

    ¬øPor qu√© puede ayudar a reducir el overfitting? Dropout act√∫a como un mecanismo de regularizaci√≥n que introduce ruido en el entrenamiento, dificultando que el modelo memorice los datos de entrenamiento. En su lugar, lo obliga a aprender caracter√≠sticas m√°s robustas y generalizables.

    Ejemplo de implementaci√≥n en Keras

<pre><code class="python">
    model.add(tf.keras.layers.Dropout(0.5))  # Apaga el 50% de las neuronas
</code></pre>

<h4>Data Augmentation</h4>

    ¬øEn qu√© consiste? Data augmentation implica crear nuevas muestras de datos a partir de los datos originales mediante transformaciones como rotaciones, zooms, recortes, reflejos o cambios de color. Esto aumenta la diversidad del conjunto de datos sin necesidad de recopilar m√°s datos reales.

    ¬øPor qu√© puede ayudar a reducir el overfitting? Al proporcionar un conjunto de datos m√°s diverso y rico, el modelo se ve obligado a aprender patrones m√°s generales en lugar de memorizar caracter√≠sticas espec√≠ficas de los datos de entrenamiento. Esto es especialmente √∫til cuando el conjunto de datos original es peque√±o.

    Ejemplo de implementaci√≥n en Keras

<pre><code class="python">
    datagen = tf.keras.preprocessing.image.ImageDataGenerator(
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest')
    datagen.fit(x_train)
</code></pre>

<h4>Pooling</h4>

    ¬øEn qu√© consiste? Pooling, como el max pooling o el average pooling, es una t√©cnica utilizada en redes convolucionales para reducir la dimensionalidad espacial (alto y ancho) de los mapas de caracter√≠sticas. Esto se realiza seleccionando los valores m√°s importantes de regiones peque√±as del mapa de caracter√≠sticas.

    ¬øPor qu√© puede (o no) ayudar a reducir el overfitting? Pooling reduce la complejidad del modelo al disminuir el n√∫mero de par√°metros aprendidos, lo cual puede ayudar a evitar el sobreajuste. Sin embargo, su principal objetivo no es reducir el overfitting, sino capturar las caracter√≠sticas m√°s importantes mientras reduce la resoluci√≥n espacial. Su efecto en la regularizaci√≥n es m√°s un subproducto que un prop√≥sito principal.

    Ejemplo de implementaci√≥n en Keras

<pre><code class="python">
    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
</code></pre>

<h4>Conclusi√≥n</h4>

Las t√©cnicas m√°s efectivas para reducir el overfitting ser√≠an Early Stopping, Dropout y Data Augmentation, ya que atacan directamente el problema del sobreajuste:

    - Early Stopping previene un sobreentrenamiento al detenerse en el momento √≥ptimo.

    - Dropout introduce regularizaci√≥n en las capas del modelo, forz√°ndolo a aprender patrones m√°s robustos.

    - Data Augmentation incrementa la diversidad del conjunto de datos, reduciendo la probabilidad de memorizar caracter√≠sticas espec√≠ficas.

- Pooling, aunque √∫til para reducir la dimensionalidad, no est√° dise√±ado espec√≠ficamente para combatir el overfitting. Su impacto en este sentido es m√°s indirecto."
---
"Est√°s trabajando en la automatizaci√≥n de la salida de piezas de una m√°quina fresadora para que un robot cartesiano pueda coger la pieza
...trabaja con un total de 10 piezas distintas que la fresadora va construyendo

...has dise√±ado un modelo usando keras que emplea el c√≥digo.
¬øPodr√≠as identificar los 2 errores que hay en el c√≥digo, las implicaciones que tendr√≠an y c√≥mo solucionarlos? (mirar expli despu√©s)
<pre><code class="python">
model = tf.keras.models.Sequential([
    # Primera capa convolucional
    tf.keras.layers.Conv2D(64, (120, 120), activation='relu', input_shape=(128, 128, 3)),
    tf.keras.layers.MaxPooling2D((2, 2)),

    # Segunda capa convolucional
    tf.keras.layers.Conv2D(64, (120, 120), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),

    # Tercera Capa Convolucional
    tf.keras.layers.Conv2D(128, (120, 120), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),

    # Convierte las matrices a vector para que sirvan de entrada a una red neuronal totalmente conectada.
    tf.keras.layers.Flatten(),

    # Proceso de regularizaci√≥n con dropout con una desactivaci√≥n del 50% de las neuronas
    tf.keras.layers.Dropout(0.5),

    # Capa oculta de 512 neuronas
    tf.keras.layers.Dense(512, activation='relu'),

    # Capa de salida de 7 neuronas
    tf.keras.layers.Dense(7, activation='softmax')
])

model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

history = model.fit(X, y, epochs=20, verbose=1, validation_data=(X_t, y_t))

</code></pre>:
A. n√∫mero de neuronas en la salida peque√±o.
B. tama√±o del kernel en las capas convolucionales es grande.
C. n√∫mero de neuronas en la salida grande.
D. tama√±o del kernel en las capas convolucionales es peque√±o.
E. La entrada a la capa Dense tiene un formato no adecuado.";"A,B";"Errores -

Err1 - El tama√±o del kernel en las capas convolucionales es demasiado grande: (120, 120). Esto significa que cada filtro intentar√° abarcar casi toda la imagen (o una gran parte de ella), lo que es poco pr√°ctico y desperdicia la capacidad de aprendizaje del modelo.

  Reducir el tama√±o del kernel: Cambiar de (120, 120) a algo m√°s razonable, como (3, 3) o (5, 5).

Err2 - La capa de salida tiene 7 neuronas:

tf.keras.layers.Dense(7, activation='softmax')

Esto es incorrecto porque el problema implica clasificar 10 piezas distintas producidas por la fresadora. La capa de salida debe tener tantas neuronas como categor√≠as a clasificar.

"
---
"Est√°s construyendo una red neuronal profunda para trabajar con im√°genes de animales de un Zoo. Algunos ejemplos de las im√°genes de las que dispones son las siguientes

<img src="assets/animales_examen.png" />

Concretamente, el objetivo es determinar qu√© animales de especies distintas pasan tiempo juntos entre ellos.

Por eso, si hay un tigre blanco y un mono en la misma imagen, la salida de la red neuronal debe indicar que estos dos animales est√°n presentes en la imagen.

No importa que alguno de ellos aparezca m√°s de una vez.

Est√°s decidiendo qu√© funci√≥n de activaci√≥n usar en la √∫ltima capa.
¬øCu√°l crees que es la m√°s id√≥nea para ser usada en este problema? Justifica tu respuesta. (0.5 puntos responder cu√°l es la funci√≥n de activaci√≥n adecuada) (1.5 puntos determinar las razones que justifica que esa es la funci√≥n de activaci√≥n adecuada y el resto no):
A. Sigmoide.
B. Tangente Hiperb√≥lica
C. ReLU
D. Softmax.";"A";"El problema implica una clasificaci√≥n multietiqueta (multi-label classification), donde la red neuronal debe predecir de manera independiente la presencia o ausencia de cada especie de animal en una imagen.

Esto implica que:

    Cada salida de la red debe ser independiente de las dem√°s.
        Por ejemplo, la presencia de un tigre no afecta la probabilidad de que tambi√©n haya un mono.
        Esto es diferente a la clasificaci√≥n multiclase (donde una sola clase es seleccionada), que requiere que las probabilidades sumen 1 (como sucede con Softmax).

    Sigmoide es ideal para este caso porque:
        Produce una probabilidad individual para cada neurona de salida (entre 0 y 1).
        Esto permite que cada neurona indique la probabilidad de presencia de un animal en la imagen, sin depender de las otras neuronas.

<a target="_blank" href="https://ml-explained.com/blog/activation-functions-explained">
Funciones Activaci√≥n Explicadas
</a>


Razones por las que las otras funciones de activaci√≥n no son adecuadas:

    Tangente Hiperb√≥lica (tanh):
        Rango de salida: (‚àí1,1)(‚àí1,1).
        Problema: La tangente hiperb√≥lica no es adecuada para representar probabilidades, ya que los valores negativos no tienen sentido en este contexto. Adem√°s, no produce una escala directamente interpretable como "probabilidad de presencia".

    ReLU (Rectified Linear Unit):
        Rango de salida: [0,‚àû)[0,‚àû).
        Problema: Aunque produce valores positivos, ReLU no est√° limitada a un rango espec√≠fico (como 0 a 1), lo que dificulta interpretarlos como probabilidades. Adem√°s, puede producir salidas excesivamente grandes o quedarse atrapada en ceros (problema de "dying ReLU").

    Softmax:
        Rango de salida: [0,1][0,1], con la suma de todas las salidas igual a 1.
        Problema: Softmax fuerza las salidas a ser mutuamente excluyentes y a sumar 1, lo cual es ideal para clasificaci√≥n multiclase (donde una sola clase es v√°lida). Sin embargo, en este caso, los animales pueden aparecer juntos en la imagen, por lo que las salidas no deben ser excluyentes.


<b>Func Act | ¬øAdecuada? | Raz√≥n</b>

<b>Sigmoide</b> | S√≠ | Ideal para clasificaci√≥n multietiqueta: genera probabilidades independientes por salida.

<b>Tangente Hiperb√≥lica</b> | No | No produce probabilidades (rango: (-1, 1)).

<b>ReLU</b> | No | No produce probabilidades ni est√° limitada a un rango √∫til ([0, ‚àû)).

<b>Softmax</b> | No | Asume exclusividad entre clases (clasificaci√≥n multiclase), lo que no aplica en este caso.


"
---
"La t√©cnica de Data Augmentation consiste en:
A. Solo funciona con datos tabulares y es √∫til para aumentar su cantidad mediante copias exactas.
B. Es una t√©cnica que solo funciona con im√°genes y consiste en a√±adir ruido aleatorio para simular variaciones.
C. Se utiliza para aumentar artificialmente el tama√±o del conjunto de datos aplicando transformaciones a los datos existentes, como rotaciones, recortes, espejado, o ajustes de brillo.
D. Vale para diferentes tipos de datos (im√°genes, texto, audio) incluye t√©cnicas como rotaci√≥n de im√°genes, sin√≥nimos en texto o cambios de tono en audio.";"C,D";"incluye transformaciones comunes para im√°genes.
el Data Augmentation no se limita solo a im√°genes. tambi√©n se aplica a texto (sin√≥nimos, cambios en frases) y audio (ajustes de velocidad, tono, etc.)."
---
"La t√©cnica de Data Augmentation consiste en:
A. Solo es √∫til en redes densas (Dense) y funciona generando nuevas combinaciones de los pesos y sesgos de las neuronas.
B. Es una t√©cnica fundamental en redes convolucionales (CNN) para aumentar artificialmente el tama√±o del conjunto de datos aplicando transformaciones como rotaciones, recortes, espejado o ajustes de brillo en im√°genes.
C. Es exclusiva de redes recurrentes (RNN) y se usa para duplicar secuencias de texto o audio a√±adiendo peque√±as variaciones.
D. Se aplica tanto en redes convolucionales (CNN) como en redes recurrentes (RNN) y redes densas (Dense), pero las transformaciones t√≠picas var√≠an dependiendo del tipo de datos, como rotaciones en im√°genes para CNN y sin√≥nimos en texto para RNN.";"B,D";"Data Augmentation es una t√©cnica utilizada para aumentar artificialmente el tama√±o y la diversidad del conjunto de datos de entrenamiento en problemas de aprendizaje autom√°tico, especialmente en redes neuronales profundas. La idea principal es aplicar transformaciones o modificaciones a los datos existentes, generando nuevas versiones de los mismos que mantienen la informaci√≥n relevante. Esto es particularmente √∫til cuando el conjunto de datos original es peque√±o, ya que ayuda a prevenir el sobreajuste (overfitting) y mejora la capacidad del modelo para generalizar en datos nunca antes vistos.

Relaci√≥n con redes neuronales (RNN, Dense, CNN):
Data Augmentation es especialmente relevante en redes convolucionales (CNN) debido a su capacidad para aprender patrones espaciales en datos como im√°genes.

En este caso, se aplican transformaciones como rotaci√≥n, recorte, cambio de brillo, volteo horizontal o vertical, y escalado para simular diferentes perspectivas de la misma imagen. En redes recurrentes (RNN), que procesan datos secuenciales como texto o audio, se pueden usar t√©cnicas como la sustituci√≥n de palabras por sin√≥nimos, reorganizaci√≥n de frases, o cambios en la velocidad y el tono en se√±ales de audio. Aunque menos frecuente, en redes densas (Dense) tambi√©n se pueden generar datos sint√©ticos mediante interpolaciones o simulaciones en conjuntos de datos tabulares.

Ejemplos de transformaciones t√≠picas:

* En im√°genes:

    - Rotaci√≥n: Girar la imagen en ciertos grados para simular diferentes orientaciones.

    - Recorte y

    - escalado: Ampliar o reducir partes de la imagen para simular diferentes enfoques.

    - Volteo horizontal o vertical: Invertir la imagen para cubrir simetr√≠as comunes.

* En texto:

  - reemplazar palabras por sin√≥nimos,

  - eliminar palabras irrelevantes,

  - reordenar frases sin cambiar el significado

* En audio,

  - ajustes en el tono,

  - la velocidad

  - la intensidad.

Estas t√©cnicas permiten que los modelos aprendan a ser m√°s robustos y generalicen mejor ante variaciones de los datos en el mundo real."
---
"¬øQu√© es Dropout y c√≥mo reduce el Overfitting?:
A. Dropout consiste en eliminar de forma permanente un porcentaje de neuronas de la red para hacerla m√°s peque√±a y eficiente.
B. Es una t√©cnica en la que se desactivan aleatoriamente algunas neuronas durante el entrenamiento, lo que fuerza a la red a no depender de neuronas espec√≠ficas y aprender representaciones m√°s generales.
C. Dropout elimina conexiones entre capas durante el entrenamiento, pero no afecta las neuronas ni las capas directamente.
D. Es una t√©cnica que se utiliza √∫nicamente en redes recurrentes (RNN) para evitar problemas relacionados con la memoria a largo plazo.";"B";"- Dropout no elimina neuronas de forma permanente, solo las "desactiva" temporalmente durante el entrenamiento.

- Dropout funciona al desactivar aleatoriamente neuronas durante el entrenamiento, lo que ayuda a la red a aprender representaciones m√°s generales y evita el sobreajuste.

- Dropout S√ç afecta directamente a las neuronas, no solo a las conexiones.

- Dropout NO es exclusivo de redes recurrentes- se aplica en redes convolucionales (CNN), densas (Dense) y recurrentes (RNN).

<a target="_blank" href="https://es.wikipedia.org/wiki/Abandono_(redes_neuronales)">
Dropout / Abandono RRNN
</a>

<h4>¬øQu√© es Dropout?</h4>

Dropout es una t√©cnica regularizadora utilizada en redes neuronales para reducir el riesgo de overfitting (sobreajuste). Durante el entrenamiento, se desactivan aleatoriamente un porcentaje de neuronas en cada iteraci√≥n, lo que significa que estas neuronas no contribuyen ni al c√°lculo hacia adelante (forward pass) ni a la retropropagaci√≥n (backpropagation). Al hacer esto, se fuerza a la red a no depender excesivamente de neuronas espec√≠ficas, oblig√°ndola a aprender patrones m√°s generales y robustos en los datos de entrada.

<h4>¬øC√≥mo reduce el overfitting?</h4>

Al apagar neuronas de forma aleatoria, Dropout simula el entrenamiento de m√∫ltiples redes neuronales diferentes (un enfoque conocido como ensamble impl√≠cito). Como cada iteraci√≥n utiliza un subconjunto diferente de neuronas, la red no se "memoriza" los datos de entrenamiento, sino que aprende caracter√≠sticas m√°s universales. Durante la fase de inferencia, Dropout no se aplica en su lugar, todas las neuronas est√°n activas y sus pesos se escalan adecuadamente para reflejar las contribuciones promedio durante el entrenamiento. Esto resulta en un modelo m√°s generalizable y con menor riesgo de sobreajuste."
---
"¬øCu√°l es la caracter√≠stica principal de cada tipo de aprendizaje autom√°tico?:
A. Aprendizaje supervisado - aprender patrones a partir de datos etiquetados, donde cada entrada tiene su correspondiente salida esperada. Clasificar correos electr√≥nicos como spam o no spam.
B. Aprendizaje no supervisado- aprender patrones a partir de datos no etiquetados, agrupando o descubriendo estructuras subyacentes. Agrupar clientes seg√∫n su comportamiento de compra.
C. Aprendizaje por refuerzo - entrenar un modelo para tomar decisiones secuenciales, obteniendo recompensas o penalizaciones. Ense√±ar a un robot a navegar por un entorno evitando obst√°culos.
D. Aprendizaje supervisado y no supervisado son equivalentes";"A,B,C";"- El aprendizaje supervisado requiere datos etiquetados y tiene aplicaciones como clasificaci√≥n y regresi√≥n.

- El aprendizaje no supervisado se centra en datos sin etiquetas, buscando agrupar o reducir dimensionalidad.

- El aprendizaje por refuerzo es un enfoque basado en interacciones y recompensas para optimizar una pol√≠tica de acci√≥n.

- Supervisado y no supervisado son m√©todos distintos uno requiere etiquetas y el otro no.

<h4>Aprendizaje supervisado</h4>

El aprendizaje supervisado se basa en un conjunto de datos etiquetados, donde cada entrada tiene una salida correspondiente conocida. El objetivo es que el modelo aprenda a mapear las entradas a las salidas para predecir correctamente nuevos datos no vistos. Este tipo de aprendizaje se utiliza en tareas como clasificaci√≥n, por ejemplo, clasificar correos electr√≥nicos como spam o no spam, y regresi√≥n, como predecir precios de casas. Requiere un gran volumen de datos etiquetados, lo cual puede ser costoso o dif√≠cil de obtener.

<h4>Aprendizaje no supervisado</h4>

En el aprendizaje no supervisado, los datos no tienen etiquetas asociadas, y el modelo debe identificar patrones, estructuras o agrupaciones inherentes en los datos. Este enfoque se utiliza para problemas como el clustering o la reducci√≥n de dimensionalidad. Un ejemplo com√∫n es agrupar clientes en segmentos de mercado seg√∫n su comportamiento de compra o descubrir grupos de genes similares en biolog√≠a. Este tipo de aprendizaje es √∫til cuando no es factible obtener etiquetas para los datos.

<h4>Aprendizaje por refuerzo</h4>

El aprendizaje por refuerzo es un enfoque basado en la interacci√≥n de un agente con un entorno, donde el agente toma decisiones secuenciales y recibe recompensas o penalizaciones basadas en sus acciones. El objetivo es aprender una pol√≠tica √≥ptima que maximice las recompensas acumuladas. Este m√©todo se utiliza en problemas como ense√±ar a un robot a navegar por un entorno, entrenar agentes para jugar videojuegos o desarrollar sistemas aut√≥nomos como autos que conducen solos. Es especialmente √∫til para problemas donde las decisiones influyen en el resultado a largo plazo.
---
"¬øCu√°l es una caracter√≠stica distintiva de las redes neuronales recurrentes LSTM en comparaci√≥n con las redes recurrentes tradicionales?:
A. Las LSTM no tienen un estado interno, solo utilizan el estado oculto como en las redes recurrentes tradicionales.
B. Las LSTM introducen un estado interno llamado cell state que les permite recordar informaci√≥n durante periodos de tiempo m√°s largos.
C. Las LSTM eliminan el estado oculto y lo reemplazan completamente por el cell state.
D. Las LSTM funcionan igual que las redes recurrentes tradicionales pero con mayor profundidad en las capas.";"B";"las LSTM introducen un cell state que les permite manejar informaci√≥n de largo plazo, evitando problemas como el desvanecimiento del gradiente.
- el funcionamiento de las LSTM es distinto al de las redes recurrentes tradicionales, ya que incorporan mecanismos como puertas de entrada, salida y olvido.
- las LSTM mantienen tanto el estado interno (cell state) como el estado oculto (hidden state)
-  las LSTM s√≠ tienen un estado interno adicional (cell state), adem√°s del estado oculto (hidden state).

<a target="_blank" href="https://www.geeksforgeeks.org/whats-the-difference-between-the-cell-and-hidden-state-in-lstm">LSTM Hidden State</a>

<a target="_blank" href="https://dotneteers.net/understanding-lstm-networks-long-short-term-memory-networks/">Understanding LSTM</a>
"
---
"¬øCu√°les son los factores que intervienen en el c√°lculo del cell state y del hidden state en una LSTM y qu√© informaci√≥n aportan?:
A. Puerta de entrada, puerta de olvido, vector de entrada modificado y puerta de salida- Cada una de estas puertas controla aspectos clave del flujo de informaci√≥n en la LSTM, como agregar, descartar y enviar informaci√≥n.
B. Solo se usan dos factores cell state y hidden state - El c√°lculo en LSTM no utiliza puertas, solo el estado de celda y el estado oculto.
C. Puerta de entrada controla cu√°nta informaci√≥n nueva ser√° agregada, puerta de olvido decide cu√°nta informaci√≥n previa debe ser descartada, vector de entrada modificado propone nueva informaci√≥n para el cell state, y puerta de salida decide cu√°nta informaci√≥n del cell state se enviar√° al hidden state
D. Puerta de entrada controla la entrada, puerta de olvido decide cu√°nta informaci√≥n nueva agregar, vector de entrada elimina informaci√≥n irrelevante y puerta de salida descarta informaci√≥n del hidden state";"A,C";"Las redes neuronales Long Short-Term Memory (LSTM) tienen un mecanismo de puertas que regula el flujo de informaci√≥n dentro de la red. Estas puertas permiten que las LSTM manejen de manera eficiente tanto la memoria de corto como de largo plazo, resolviendo problemas comunes de las redes recurrentes tradicionales, como el desvanecimiento del gradiente. A continuaci√≥n, se explican las cuatro principales componentes:

    Puerta de entrada (Input Gate):
    La puerta de entrada controla qu√© informaci√≥n nueva, proveniente de la entrada actual y del estado oculto previo, debe ser a√±adida al estado interno (cell state). Utiliza una activaci√≥n sigmoide para determinar qu√© partes de la informaci√≥n pasan y una activaci√≥n tanh para procesar la informaci√≥n propuesta (vector de entrada modificado).

    Puerta de olvido (Forget Gate):
    La puerta de olvido regula cu√°nta informaci√≥n previa del cell state debe ser descartada. Es esencial para decidir qu√© datos hist√≥ricos son irrelevantes y deben ser eliminados para mantener una memoria eficiente. Esta puerta tambi√©n utiliza una activaci√≥n sigmoide.

    Vector de entrada modificado (Candidate Vector):
    Este vector representa una versi√≥n procesada de la informaci√≥n nueva que podr√≠a a√±adirse al cell state. Se calcula aplicando una activaci√≥n tanh a la entrada actual y al estado oculto previo. Es modulado por la puerta de entrada antes de ser integrado al cell state.

    Puerta de salida (Output Gate):
    La puerta de salida controla cu√°nta informaci√≥n del cell state actual debe ser transferida al hidden state y, por lo tanto, a la salida de la red. Esto permite que la LSTM seleccione qu√© informaci√≥n es relevante para las predicciones actuales, mientras mantiene el resto en el cell state.

<a target="_blank" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM</a>

"
---
"¬øCu√°les son las ventajas de utilizar la funci√≥n de activaci√≥n ReLU en redes neuronales?:
A. Es computacionalmente eficiente, evita problemas de desvanecimiento del gradiente, y permite entrenar redes profundas. Esto se debe a su naturaleza lineal a partir de cero, lo que facilita la propagaci√≥n del gradiente.

B. Es la mejor funci√≥n de activaci√≥n porque nunca genera valores nulos y siempre propaga informaci√≥n.

C. ReLU introduce sparsity, evita problemas de saturaci√≥n en valores positivos y permite una propagaci√≥n eficiente del gradiente. Estas caracter√≠sticas la hacen ideal para redes profundas.

D. ReLU funciona igual que Softmax, ya que normaliza los valores entre 0 y 1 para cada neurona en la capa de salida.";"A,C";"- ReLU es computacionalmente eficiente porque solo realiza una operaci√≥n condicional: max(0, x).

- ReLU evita el desvanecimiento del gradiente porque no satura para valores positivos (a diferencia de sigmoide o tanh).

- Esto permite entrenar redes profundas de manera m√°s efectiva

- Aunque ReLU tiene ventajas, no es "perfecta". Puede generar valores nulos (problema de "dying ReLU") si muchas neuronas quedan inactivas.

- ReLU introduce sparsity (muchos valores activados son 0), lo que mejora la eficiencia de c√°lculo y la capacidad de generalizaci√≥n.

- Tambi√©n evita problemas de saturaci√≥n en valores positivos, lo que facilita una mejor propagaci√≥n del gradiente.

- ReLU no normaliza valores entre 0 y 1 como Softmax. ReLU simplemente devuelve 0 para valores negativos y x para valores positivos.

- La funci√≥n de activaci√≥n ReLU (Rectified Linear Unit) es ampliamente utilizada en redes neuronales debido a sus m√∫ltiples ventajas. Su principal beneficio es su eficiencia computacional, ya que la operaci√≥n max(0,x)max(0,x) es muy simple y r√°pida de calcular. Adem√°s, evita el problema del desvanecimiento del gradiente, que ocurre en funciones como sigmoide o tanh, ya que no satura para valores positivos. Esto permite que las redes neuronales profundas puedan ser entrenadas de manera efectiva.

 - Otra ventaja importante de ReLU es que introduce sparsity en la activaci√≥n de las neuronas. Muchas activaciones se convierten en 0, lo que simplifica los c√°lculos posteriores y reduce la complejidad del modelo. Sin embargo, ReLU tambi√©n tiene limitaciones, como el problema de "dying ReLU", donde algunas neuronas pueden quedarse inactivas permanentemente si reciben siempre valores negativos.

<a target="_blank" href="https://ml-explained.com/blog/activation-functions-explained">Activation functions explained</a>

<a target="_blank" href="https://towardsdatascience.com/vanishing-gradient-problem-69bf08b15484">Understanding the Vanishing Gradient Problem in Neural Networks</a>

<a target="_blank" href="https://www.deeplearningbook.org">DL Book</a>"
---
"Cu√°l ser√≠a el gradiente de la funci√≥n sigmoide con respecto a una entrada muy grande?:
A. grad ser√° cercano a cero, ya que la funci√≥n sigmoide se satura en valores altos de entrada.
B. grad ser√° exactamente igual a 1, ya que la sigmoide alcanza su m√°ximo.
C. grad ser√° negativo, ya que la sigmoide invierte su direcci√≥n en valores altos.
D. grad ser√° muy grande, ya que la funci√≥n crece exponencialmente para entradas grandes.";"A";"Cuando la entrada es muy grande (positiva), la salida de la sigmoide se acerca a 1, lo que significa que el gradiente œÉ(z)(1‚àíœÉ(z))œÉ(z)(1‚àíœÉ(z)) se aproxima a 1‚ãÖ(1‚àí1)=01‚ãÖ(1‚àí1)=0.

Esto refleja la saturaci√≥n de la funci√≥n en valores altos, lo que genera un gradiente peque√±o.

- El gradiente nunca es exactamente 1 en los extremos de la sigmoide. Solo alcanza valores cercanos a 1 cuando la entrada est√° cerca de 0.

- El gradiente no puede ser negativo porque œÉ(z)(1‚àíœÉ(z))œÉ(z)(1‚àíœÉ(z)) siempre es positivo.

- Aunque la funci√≥n sigmoide tiene un componente exponencial, su gradiente disminuye a medida que la salida se satura, no aumenta.

El gradiente de la funci√≥n sigmoide est√° dado por:

<img src="assets/sigmoid_gradient.png"/>

Cuando zz es muy grande (positiva), œÉ(z)‚âà1œÉ(z)‚âà1, y el t√©rmino (1‚àíœÉ(z))(1‚àíœÉ(z)) se aproxima a 0. Esto hace que el gradiente sea muy peque√±o, lo que puede causar problemas como el desvanecimiento del gradiente en redes profundas. Este es uno de los motivos por los que la sigmoide se usa menos en redes profundas en comparaci√≥n con ReLU o funciones similares.

<a target="_blank" href="https://ml-explained.com/blog/activation-functions-explained">Activation functions explained</a>"
---
"<img src="assets/sigmoid_graph.png"/>

¬øPor qu√© el comportamiento de la funci√≥n sigmoide podr√≠a suponer un problema en el entrenamiento de redes neuronales?:
A. sig satura en valores extremos, genera gradientes muy peque√±os y provoca desvanecimiento del gradiente en redes profundas.

B. sig genera gradientes negativos en los valores extremos, impide la convergencia del modelo.

C. sig no permite valores negativos, elimina patrones importantes en los datos de entrada.

D. sig es computacionalmente ineficiente en comparaci√≥n con funciones como ReLU, y requiere m√°s tiempo para entrenar RRNN profun.";"A,D";"- La funci√≥n sigmoide satura en valores extremos (cercanos a 0 o 1), lo que genera gradientes muy peque√±os (œÉ(z)(1‚àíœÉ(z))‚âà0œÉ(z)(1‚àíœÉ(z))‚âà0) en estas regiones. Esto provoca el problema conocido como desvanecimiento del gradiente, donde los par√°metros de las capas iniciales de la red neuronal dejan de actualizarse eficazmente, dificultando el entrenamiento de redes profundas.

- El gradiente de la sigmoide nunca es negativo porque est√° definido como œÉ(z)(1‚àíœÉ(z))œÉ(z)(1‚àíœÉ(z)), que siempre es positivo para cualquier valor de zz.

<img src="assets/sigmoid_gradient.png"/>

- La sigmoide no elimina patrones importantes porque permite valores de salida entre 0 y 1. Aunque no admite valores negativos en la salida, esto no elimina informaci√≥n.

- El c√°lculo de la sigmoide implica la evaluaci√≥n de una funci√≥n exponencial, lo que la hace menos eficiente computacionalmente que funciones m√°s simples como ReLU. Esto puede aumentar el tiempo necesario para entrenar redes profundas, especialmente en arquitecturas modernas con millones de par√°metros.

El problema principal de la funci√≥n sigmoide radica en su tendencia a saturarse en los valores extremos, donde el gradiente se aproxima a 0. Esto hace que las actualizaciones de los pesos durante el entrenamiento sean insignificantes en capas iniciales, ralentizando el aprendizaje o incluso deteni√©ndolo en redes profundas. Adem√°s, la computaci√≥n de la funci√≥n sigmoide es m√°s costosa en t√©rminos computacionales, lo que la hace menos pr√°ctica frente a alternativas como ReLU o Leaky ReLU. Por estas razones, la sigmoide se usa principalmente en salidas de redes (como clasificaci√≥n binaria), pero rara vez en capas ocultas de redes profundas.

<a target="_blank" href="https://ml-explained.com/blog/activation-functions-explained">Activation functions explained</a>"
---
"¬øC√≥mo puede la funci√≥n de activaci√≥n ReLU solventar los problemas de la funci√≥n sigmoide durante el entrenamiento?:
A. ReLU no se satura en valores positivos, permite que el grad. se mantenga constante en gran parte de su dominio, evitando el desvanecimiento del grad.

B. ReLU utiliza la fun exponenc internamente, mejorando el c√°lculo del grad. en redes profundas.

C. ReLU devuelve valores exactos de 0 o mayores en los datos negativos, evitando errores durante el entrenamiento.

D. ReLU(z) = max(0, z) permite un c√°lculo m√°s eficiente computacionalmente, no requiere operaciones costosas como exponenciales o divisiones, y mantiene grads √∫tiles en redes profundas.";"A,D";"- ReLU no tiene la tendencia a saturarse como la sigmoide. Para valores positivos de entrada, el gradiente de ReLU es constante (1), mientras que para valores negativos es 0. Esto ayuda a evitar el problema del desvanecimiento del gradiente, especialmente en redes profundas.

- ReLU no utiliza la funci√≥n exponencial en su c√°lculo. Su simplicidad (max(0, z)) es una de las razones por las que es computacionalmente eficiente.

- Aunque ReLU devuelve 0 para valores negativos, esto puede causar el problema de "dying ReLU", donde algunas neuronas quedan permanentemente inactivas. Este comportamiento no evita errores, sino que es una limitaci√≥n de ReLU.

- ReLU es computacionalmente eficiente porque no involucra c√°lculos complejos como exponenciales o divisiones, a diferencia de sigmoide. Esto la hace ideal para entrenar redes profundas r√°pidamente mientras mantiene gradientes √∫tiles en gran parte del dominio de la entrada.

<img src="assets/relu_gelu_graph.png"/>
<img src="assets/sigmoid_graph.png"/>
<img src="assets/relu_graph.png"/>

- La funci√≥n ReLU se define como ReLU(z)=max‚Å°(0,z)ReLU(z)=max(0,z). A diferencia de la sigmoide, que tiende a saturarse y generar gradientes muy peque√±os en valores extremos, ReLU mantiene un gradiente constante de 11 para entradas positivas. Esto permite que las actualizaciones de los pesos sean significativas, evitando el problema de desvanecimiento del gradiente, lo que es crucial para entrenar redes profundas.

- Adem√°s, ReLU es mucho m√°s eficiente computacionalmente, ya que no requiere c√°lculos costosos como exponentes. Sin embargo, ReLU no es perfecta y puede causar el problema de "dying ReLU", donde algunas neuronas quedan inactivas para siempre si reciben entradas negativas constantemente. Variantes como Leaky ReLU solucionan este problema permitiendo un gradiente peque√±o en valores negativos.

<a target="_blank" href="https://ml-explained.com/blog/activation-functions-explained">Activation functions explained</a>

<a target="_blank" href="https://www.deeplearningbook.org">DL Book</a>
"
---
"¬øCu√°les son las ventajas de utilizar Redes Neuronales Convolucionales (CNN) para trabajar con im√°genes?:
A. Capturan caracter√≠sticas espaciales y patrones locales autom√°ticamente utilizando filtros y capas convolucionales. Esto elimina la necesidad de dise√±ar manualmente caracter√≠sticas relevantes.

B. Reducen significativamente la cantidad de par√°metros mediante el uso de convoluciones y pooling, lo que permite trabajar con im√°genes grandes sin necesidad de computaci√≥n intensiva.

C. Son adecuadas para datos secuenciales como texto y series temporales, ya que las CNN procesan las entradas en orden.

D. Permiten la reutilizaci√≥n de pesos, lo que optimiza el entrenamiento y mejora la generalizaci√≥n en problemas de visi√≥n por computadora.";"A,B,D";"- Las CNN son especialmente dise√±adas para trabajar con im√°genes porque utilizan filtros que capturan autom√°ticamente patrones locales y caracter√≠sticas espaciales como bordes, texturas o formas. Esto elimina la necesidad de dise√±ar manualmente estas caracter√≠sticas, lo que era com√∫n en los m√©todos tradicionales.

- Mediante el uso de operaciones de convoluci√≥n y pooling, las CNN reducen la cantidad de par√°metros necesarios, haciendo que el modelo sea m√°s eficiente y menos propenso al sobreajuste. Esto es clave para trabajar con im√°genes grandes.

- Las CNN no est√°n dise√±adas espec√≠ficamente para datos secuenciales como texto o series temporales. Este tipo de datos se maneja mejor con redes recurrentes (RNN) o transformadores. Aunque se pueden adaptar para estos casos, no es su ventaja principal.

- Las CNN reutilizan los mismos filtros en diferentes partes de la imagen, lo que reduce los c√°lculos y mejora la generalizaci√≥n, ya que el modelo aprende caracter√≠sticas comunes en toda la imagen. Esto es crucial para problemas de visi√≥n por computadora.

- Las redes convolucionales son ideales para im√°genes porque capturan caracter√≠sticas autom√°ticamente, son computacionalmente eficientes y permiten la reutilizaci√≥n de pesos. Estas ventajas las han convertido en el est√°ndar para problemas de visi√≥n por computadora.

<a target="_blank" href="https://data-universe.org/redes-neuronales-convolucionales-aplicaciones-en-procesamiento-de-imagenes/">CNN procesamiento im√°genes</a>

<a target="_blank" href="https://lovtechnology.com/redes-neuronales-convolucionales-para-vision-por-computadora/">CNN visi√≥n por computadora</a>

<a target="_blank" href="https://cadenaser.com/nacional/2024/08/27/cientificos-espanoles-combinan-ia-con-mejores-microscopios-para-detectar-antes-el-cancer-y-las-infecciones-cadena-ser/">Detecci√≥n enfermedades</a>

"
---
"¬øQu√© tipo de red neuronal usar√≠as para trabajar con datos que tienen un alto componente secuencial como series temporales y por qu√©?:
A. Redes Recurrentes (RNN) - ideales para datos secuenciales porque tienen conexiones recurrentes que les permiten retener informaci√≥n de pasos anteriores y aprender dependencias temporales.
B. Redes Convolucionales (CNN)- ideales para capturar patrones locales en datos secuenciales, como las tendencias cortas en series temporales.
C. Redes Neuronales Densas (Dense)- estas redes generalizan bien a cualquier tipo de dato, incluyendo secuencias, al procesar cada entrada independientemente.
D. Redes GAN (Generative Adversarial Networks)- son muy eficaces para generar datos sint√©ticos, pero tambi√©n pueden aprender dependencias temporales en series.";"A";"- Las Redes Recurrentes (RNN), y sus variantes como LSTM (Long Short-Term Memory) y GRU (Gated Recurrent Units), son espec√≠ficamente dise√±adas para trabajar con datos secuenciales como series temporales. Su principal caracter√≠stica es la capacidad de retener informaci√≥n a trav√©s del tiempo mediante conexiones recurrentes, lo que les permite aprender dependencias temporales y patrones a largo plazo.


- Aunque las CNN pueden ser adaptadas para trabajar con datos secuenciales, no est√°n dise√±adas para capturar dependencias temporales expl√≠citas. Son m√°s adecuadas para datos espaciales, como im√°genes, donde el orden no es tan crucial.

- Las redes densas procesan cada entrada de forma independiente y no tienen mecanismos para aprender relaciones temporales entre datos. Por lo tanto, no son ideales para series temporales.

- Las GAN son redes generativas y no est√°n dise√±adas para aprender dependencias temporales directamente. Su prop√≥sito principal es generar nuevos datos a partir de un conjunto de entrenamiento, como im√°genes o audio, pero no modelan expl√≠citamente secuencias.

- Las redes recurrentes (RNN) se destacan por su capacidad de retener informaci√≥n previa a trav√©s de un estado oculto que se actualiza en cada paso de la secuencia. Esto las hace especialmente √∫tiles para tareas como:

-     Predicci√≥n de series temporales.
-     Traducci√≥n autom√°tica.
-     Reconocimiento de voz.
-     Procesamiento de texto.

Las variantes como LSTM y GRU superan los problemas de las RNN tradicionales, como el desvanecimiento y explosi√≥n del gradiente, al introducir mecanismos de control (puertas) para gestionar qu√© informaci√≥n se retiene o se descarta en cada paso.

<a target="_blank" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTMs</a>"
---
"¬øQu√© tipo de red neuronal usar√≠as para generar obras de arte √∫nicas y c√≥mo funciona internamente esta arquitectura?:
A. Redes Generativas Adversariales (GAN) - utilizan un modelo generador para crear datos nuevos y un modelo discriminador que eval√∫a si los datos generados son reales o falsos, logrando mejorar iterativamente la calidad de las obras.
B. Redes Recurrentes (RNN) - retienen informaci√≥n a trav√©s del tiempo, lo que permite generar arte visual con patrones secuenciales √∫nicos.
C. Redes Convolucionales (CNN) - perfectas para generar arte porque extraen caracter√≠sticas locales de im√°genes y las combinan para crear nuevas obras.
D. Redes Densas (Dense) - redes densas porque procesan todos los datos de entrada de forma independiente, generando obras de arte a partir de combinaciones aleatorias de p√≠xeles.";"A";"- Las Redes Generativas Adversariales (GAN) son el enfoque ideal para generar arte √∫nico desde cero. Utilizan dos redes: un generador, que crea im√°genes nuevas, y un discriminador, que eval√∫a si las im√°genes generadas son realistas. Este enfoque de "competencia" permite al generador mejorar continuamente, resultando en obras de arte √∫nicas y de alta calidad.


- Las Redes Recurrentes (RNN) son m√°s adecuadas para datos secuenciales como texto, audio o series temporales. No est√°n dise√±adas para generar im√°genes o arte visual.


- Aunque las Redes Convolucionales (CNN) son excelentes para procesar y analizar im√°genes, no est√°n dise√±adas para generar nuevas im√°genes desde cero. Sin embargo, las GAN suelen incluir CNN en su arquitectura para trabajar con im√°genes.

- Las Redes Densas (Dense) no son pr√°cticas para generar im√°genes, ya que no tienen mecanismos para capturar la estructura espacial de las im√°genes ni para generar datos con coherencia visual.

<h4>GAN</h4>

Las GAN (Redes Generativas Adversariales) constan de dos componentes principales:

-    Generador:
    Este modelo toma un vector de ruido aleatorio como entrada y genera una imagen nueva. Inicialmente, las im√°genes generadas son aleatorias y no tienen sentido, pero el generador mejora progresivamente durante el entrenamiento.

-    Discriminador:
    Este modelo clasifica las im√°genes como "reales" (extra√≠das del conjunto de datos) o "falsas" (generadas por el generador). Su objetivo es detectar las im√°genes falsas producidas por el generador.

* Ambas redes se entrenan de manera adversarial: el generador intenta enga√±ar al discriminador creando im√°genes m√°s realistas, mientras que el discriminador intenta mejorar en la detecci√≥n de im√°genes falsas. Este proceso iterativo mejora continuamente la calidad de las im√°genes generadas. Las GAN han sido ampliamente utilizadas para generar arte, im√°genes fotorrealistas, videos y m√°s.


<a target="_blank" href="https://inteligenciaartificial360.com/fundamentos-ia/redes-adversarias-generativas-gan-fundamentos-y-aplicaciones/">GAN</a>

<a target="_blank" href="https://iccsi.com.ar/gans-inteligencia-artificial/">GAN IA</a>

<a target="_blank" href="https://lovtechnology.com/redes-generativas-adversarias-gans-creando-contenido-artificial-realista/">Creando con GAN</a>

<a target="_blank" href="https://arxiv.org/abs/1406.2661">art√≠culo original GAN</a>

"






